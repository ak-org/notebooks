{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transferlearning_resnet50_cifar10_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ak-org/notebooks/blob/master/transferlearning_resnet50_cifar10_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZTaGNOU6C3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "0151eea9-dc8b-4776-d5d2-3fadbd779245"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 80kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.1.7)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.16.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.2)\n",
            "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0.0-rc1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0.0-rc1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 48.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.33.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (41.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (0.15.6)\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36EO_Y6x6Kq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50     import ResNet50\n",
        "from tensorflow.keras.applications.vgg16        import VGG16\n",
        "from tensorflow.keras.applications.vgg19        import VGG19\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense, AveragePooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as incv3_preprocess_input\n",
        "from tensorflow.keras.applications.resnet50     import preprocess_input as resnet50_preprocess_input\n",
        "from tensorflow.keras.applications.vgg16        import preprocess_input as vgg16_preprocess_input\n",
        "from tensorflow.keras.applications.vgg19        import preprocess_input as vgg19_preprocess_input\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def custom_resnet_cifar(img_d = 128, img_c= 3):\n",
        "    conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(img_d, img_d, img_c))\n",
        "    model = models.Sequential()\n",
        "    model.add(conv_base)\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
        "    print(model.summary())\n",
        "    return model \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr9O0mlf6ZOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1434639-a8aa-42f8-dd45-9bbd67bc9e18"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiAwvhDZ6dUQ",
        "colab_type": "code",
        "outputId": "f90f44f4-d416-4131-998c-e711428b241f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "onehot_y_train = to_categorical(y_train, 10)\n",
        "onehot_y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print( X_train.shape, y_train.shape,  X_test.shape, y_test.shape )\n",
        "\n",
        "upscaled_x_train = tf.keras.backend.resize_images(X_train, \n",
        "                                                  height_factor = 4, \n",
        "                                                  width_factor = 4, \n",
        "                                                  data_format = \"channels_last\")\n",
        "\n",
        "## preprocess input\n",
        "print(\"Pre processing inputs\")\n",
        "upscaled_x_train = resnet50_preprocess_input(upscaled_x_train)\n",
        "print(upscaled_x_train.shape)\n",
        "print(\"Building custom model\")\n",
        "custom_model = custom_resnet_cifar()\n",
        "print(\"Training\")\n",
        "history = custom_model.fit(upscaled_x_train, onehot_y_train, \n",
        "                           epochs=5, batch_size=20,\n",
        "                           shuffle = True, \n",
        "                           validation_split=0.2)\n",
        "custom_model.save('cifar_resnet_model_v2.h5')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
            "Pre processing inputs\n",
            "(50000, 128, 128, 3)\n",
            "Building custom model\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 4, 4, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32768)             131072    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               4194432   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 27,922,890\n",
            "Trainable params: 27,803,850\n",
            "Non-trainable params: 119,040\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "40000/40000 [==============================] - 600s 15ms/sample - loss: 0.2655 - acc: 0.9080 - val_loss: 0.1168 - val_acc: 0.9597\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 575s 14ms/sample - loss: 0.1685 - acc: 0.9401 - val_loss: 0.0723 - val_acc: 0.9765\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 576s 14ms/sample - loss: 0.1317 - acc: 0.9550 - val_loss: 0.0555 - val_acc: 0.9823\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 576s 14ms/sample - loss: 0.1085 - acc: 0.9648 - val_loss: 0.0492 - val_acc: 0.9847\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 576s 14ms/sample - loss: 0.0912 - acc: 0.9712 - val_loss: 0.0458 - val_acc: 0.9856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-yBvVIZ81KX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e68a54c-6b0c-477b-8b19-eaca4667d4c5"
      },
      "source": [
        "upscaled_x_test = tf.keras.backend.resize_images(X_test, \n",
        "                                                  height_factor = 4, \n",
        "                                                  width_factor = 4, \n",
        "                                                  data_format = \"channels_last\")\n",
        "\n",
        "## preprocess input\n",
        "print(\"Pre processing test images.\")\n",
        "upscaled_x_test = resnet50_preprocess_input(upscaled_x_test)\n",
        "print(upscaled_x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre processing test images.\n",
            "(10000, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0Yc2ctJ9eO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "upscaled_x_test = np.array(upscaled_x_test)\n",
        "\n",
        "y_pred = custom_model.predict_classes(upscaled_x_test.astype(float), batch_size= 20)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWFgvff3sPSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "f26b75c2-8110-40c8-d8a6-4b887a2693f7"
      },
      "source": [
        "\n",
        "matrix = confusion_matrix(y_test[:,0], y_pred)\n",
        "print(\"Confusion Matrix\")\n",
        "print(matrix)\n",
        "acc = accuracy_score(y_test[:,0], y_pred)\n",
        "print(\"Accuracy : {}\".format(acc * 100.0))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[954   3   6   2   0   0   3   2  22   8]\n",
            " [  5 958   0   0   0   0   0   2   2  33]\n",
            " [ 17   0 924  19  21   3   5   7   4   0]\n",
            " [  5   1  18 888  13  49  16   5   3   2]\n",
            " [  4   2  22  27 904   6   6  23   6   0]\n",
            " [  0   0  11 111  16 837   6  16   3   0]\n",
            " [  5   0  14  16   3   4 951   2   5   0]\n",
            " [  5   0   6  12  16  14   0 946   0   1]\n",
            " [ 25   8   1   0   0   0   1   0 963   2]\n",
            " [  6  25   1   2   0   0   0   1  10 955]]\n",
            "Accuracy : 92.80000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}